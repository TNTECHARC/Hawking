<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Hawking : Intelligent Ground Vehicle Competition Project">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Hawking</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/TNTECHARC/Hawking">View on GitHub</a>

          <h1 id="project_title">Hawking</h1>
          <h2 id="project_tagline">Intelligent Ground Vehicle Competition Project</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/TNTECHARC/Hawking/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/TNTECHARC/Hawking/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="hawking" class="anchor" href="#hawking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hawking</h1>

<p>The Intelligent Ground Vehicle Competition has three main parts:</p>

<ul>
<li>Waypoint navigation</li>
<li>White line recognition</li>
<li>Obstacle avoidance</li>
</ul>

<p>In view of these elements, which are difficult to conceptually handle as a whole, I've decided to handle these as separate pieces of a whole. Therefore, there are five intertwined projects. The projects are listed here along with a summary of their goals.</p>

<h2>
<a id="waypoint-navigation" class="anchor" href="#waypoint-navigation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Waypoint navigation</h2>

<p><strong>Goal</strong>:
Given a continuous input of GPS and IMU data, filter the data and output the robot's position relative to the starting point and the direction to the next waypoint.</p>

<p><strong>Possible implementation</strong>:
Ideally, a complex mathematical filter combining IMU and GPS data would be great (if there is such an equation). But initially, just using raw GPS data would be fine and evaluation of other techniques can come later. A 3d vector could be a great way to represent relative positions and directions.</p>

<p><strong>Sensors</strong>:</p>

<ul>
<li>GPS</li>
<li>IMU</li>
</ul>

<p><strong>Responsibilities</strong>:
Everything listed in the goals. The current short term goal is to get a prototype running with GPS asap. IMU can be integrated slowly. Also, choose the data type to represent relative positions and waypoints.</p>

<h2>
<a id="white-line-recognition" class="anchor" href="#white-line-recognition" aria-hidden="true"><span class="octicon octicon-link"></span></a>White line recognition</h2>

<p><strong>Goal</strong>:
Given continuous input from a webcam, an unsteady base, and continuously changing light conditions, recognize white lines on grass (similar to soccer field lines) with scattered dirt patches.</p>

<p><strong>Possible implementation</strong>:
OpenCV has most of the necessary commands and image manipulation. Custom image filters should not be the first resort.</p>

<p><strong>Sensors</strong>:</p>

<ul>
<li>Camera</li>
</ul>

<p><strong>Responsibilities</strong>:
Everything listed in the goals. A good place to start is following a line of tape on the floor which is continuous unbroken color in steady light conditions and a smooth floor. Also, formulate the data to represent white lines. (Some way to represent line or curve segment equations)</p>

<h2>
<a id="obstacle-avoidance" class="anchor" href="#obstacle-avoidance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Obstacle avoidance</h2>

<p><strong>Goal</strong>:
Given continuous input from a Lidar scanner, filter the scan to remove "ghost" or false readings. Use the scans to determine local safe paths.</p>

<p><strong>Possible implementation</strong>:
Kalman filters and Monte Carlo localization is one of the most advanced possibilities. The more likely and easier method is to just use raw data and a smooth filter.</p>

<p><strong>Sensors</strong>:</p>

<ul>
<li>A Lidar scanner (either the Hokuyo or the SICK)</li>
</ul>

<p><strong>Responsibilities</strong>:
Everything listed in the goals. A good starting point is a reflex agent (no memory) to avoid immediate obstacles. Also, output the filtered scan.</p>

<h2>
<a id="mapping" class="anchor" href="#mapping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mapping</h2>

<p><strong>Goal</strong>:
Given all the filtered outputs from the above three modules, construct a cohesive map of the environment for the purposes of finding a path through the environment.</p>

<p><strong>Possible implementation</strong>:
A dynamic discrete probability grid where each cell represents the probability that there is an obstacle or white line there. The grid would be constantly updated as new sensor information is processed. A heuristic search function combined with rudimentary motion planning would determine the route to follow to the next waypoint. Since the grid would need to be dynamic, a quadtree could be a space efficient way to handle vast amounts of area.</p>

<p><strong>Sensors</strong>:</p>

<ul>
<li>All of the above</li>
</ul>

<p><strong>Responsibilities</strong>:
Everything listed in the goals. A good starting point is using positioning information to trace the robot's progress through an empty grid before attempting to map obstacles onto the grid. Also, simple documentation will likely not suffice for this. At least a basic design document (statement of intent and outline of methods) will be required before coding begins for this.</p>

<h2>
<a id="hardware-drivers" class="anchor" href="#hardware-drivers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware drivers</h2>

<p><strong>Goal</strong>:
Write the Ubuntu serial/usb hardware drivers to interface with each sensor and actuator. The sensors have priority over the actuators.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Hawking maintained by <a href="https://github.com/TNTECHARC">TNTECHARC</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
